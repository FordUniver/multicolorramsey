%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

\begin{theorem}\label{thm:Ramsey:multicolour}
  For each $r \ge 2$, there exists $\delta = \delta(r) > 0$ such that 
  %
  \begin{equation*}
    R_r(k) \le e^{-\delta k} r^{rk}
  \end{equation*} 
  %
  for all sufficiently large $k \in \N$. 
\end{theorem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}

%---------------------------------------------------------------------------------------------------
\subsection{Graphs and colourings}

\begin{definition}
  \label{def:edge-colouring}
  \lean{SimpleGraph.EdgeColoring}
  \leanok
  An edge colouring of a graph $G$ with colours $C$ is a map from the edge set $E(G)$ to $C$.
\end{definition}

\begin{definition}
  \label{def:colour-neighborhood}
  \uses{def:edge-colouring}
  \lean{SimpleGraph.EdgeColoring.coloredNeighborSet}
  \leanok
  Given an edge colouring, we write $N_i(u)$ to denote the neighbourhood of vertex $u$ in colour $i$.
\end{definition}

\begin{definition}
  \label{def:p}
  \uses{def:colour-neighborhood}
  Let $r, n\in\N$. Given sets $X,Y \subset V(K_n)$ and a colour $i \in [r]$, define
  $$p_i(X,Y) = \min\bigg\{ \frac{|N_i(x) \cap Y|}{|Y|} : x \in X \bigg\},$$
\end{definition}


%---------------------------------------------------------------------------------------------------
\subsection{Multinomial coefficients}

\begin{lemma}[Lemma A.1 in Balister et al.]  
  \label{lem:multibounds}
  For each $k,t,r \in \N$ with $3 \le t \le k$, we have
  $$\binom{rk-t}{k,\dots,k,k-t} \le e^{-(r-1)t^2/3rk} r^{rk-t}.$$
\end{lemma}
  
\begin{proof}
  To prove this, observe that 
  $$\binom{rk-t}{k,\dots,k,k-t} \binom{rk}{k,\dots,k}^{-1} = \, \prod_{i = 0}^{t - 1} \frac{k - i}{rk - i} = r^{-t} \,\prod_{i = 0}^{t-1} \bigg( 1 - \frac{(r-1)i}{rk - i} \bigg) \le r^{-t} \cdot e^{-(r-1)t^2/3rk}.$$
  Since $\binom{rk}{k,\dots,k} \le r^{rk}$, the claimed bound follows.
\end{proof}


%---------------------------------------------------------------------------------------------------
\subsection{Trigonometry}

\begin{definition}
  \label{def:coshsqrt}
  \lean{coshsqrt}
  \leanok
  Define $\cosh \sqrt{x}$ via its Taylor expansion
  $$\cosh\sqrt{x} = \sum_{n = 0}^\infty \frac{x^n}{(2n)!}.$$
\end{definition}

\begin{lemma}
  \label{lem:le-coshsqrt}
  \uses{def:coshsqrt}
  \lean{le_coshsqrt}
  For all $x \in \R$, it is $1 \le 2 + \cosh\sqrt{x}$.
\end{lemma}
\begin{proof}
  When $x$ is negative, we use $\cosh \sqrt{x} = \cos \sqrt{-x}\ge -1$. When $x$ is positive this is implied by the fact that all coefficients in the power series of $\cosh \sqrt{x}$ are positive.
\end{proof}

\begin{lemma}
  \label{lem:coshsqrt-bd-pos}
  \uses{def:coshsqrt}
  $x \le 2 + \cosh \sqrt{x} \le 3 e^{\sqrt{x}}$ for every $x > 0$.
\end{lemma}
\begin{proof}
  For the lower-bound, using the fact that $x>0$ and all coefficients of $\cosh \sqrt{x}$ are positive,
  \begin{equation*}
    2+\cosh \sqrt{x} - x \ge 2 - \frac{x}{2} + \frac{x^2}{24} = \frac{1}{2}+\frac{1}{24}(x-6)^2 \ge 0.
\end{equation*}
For the upper bound, we observe that because by comparing coefficients,
\begin{equation*}
  e^{\sqrt{x}} = \sum 3\frac{x^{n/2}}{n!}  \ge \cosh\sqrt{x}
\end{equation*}
Finally, $2e^{\sqrt{x}}\ge 2$ when $x>0$.
\end{proof}

\begin{lemma}
  \label{lem:coshsqrt-bd-neg}
  \uses{def:coshsqrt}
  $-1 \le \cosh \sqrt{x} \le 1$ for every $x < 0$.
\end{lemma}
\begin{proof}
  From the Taylor expansion, we get $\cosh \sqrt{x} = \cos \sqrt{-x}$.
\end{proof}

\begin{definition}
  \label{def:f}
  \uses{def:coshsqrt, lem:coshsqrt-bd-neg, lem:coshsqrt-bd-pos}
  \lean{f}
  Let $r \in \N$.
  \begin{equation}\label{eq:f}
    f(x_1,\dots,x_r) = \sum_{j = 1}^r x_j \prod_{i \ne j} \big( 2 + \cosh\sqrt{x_i} \big).
  \end{equation}
\end{definition}

\begin{lemma}
  \label{lem:taylor-nonneg}
  \uses{def:f}
  All of the coefficients of the Taylor expansion of $f$ are non-negative.
\end{lemma}
\begin{proof}
  By definition $2+\cosh\sqrt{x}$ has positive coefficients. It suffices to observe that the product and sum of two Taylor series with only positive coefficients has again positive coefficients. Since $f$ is such a combination of sums and products of Taylor series with only positive coefficients, we get the claim.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Geometric Lemma}

\begin{lemma}[Moments Lemma (Lemma 3.2 in Balister et al.)]
  \label{lem:moments}
  \lean{moments}
  Let $U$ and\/ $U'$ be i.i.d.~random variables taking values in a finite set~$X$, and let\/ $\sigma_1,\ldots,\sigma_r \colon X \to \R^n$ be arbitrary functions. Then
  $$\Ex\Big[ \big\langle \sigma_1(U),\sigma_1(U') \big\rangle^{\ell_1} \cdots \big\langle \sigma_r(U),\sigma_r(U') \big\rangle^{\ell_r} \Big] \ge 0.$$
  for every $(\ell_1,\dots,\ell_r) \in \Z^r$ with $\ell_1,\dots,\ell_r \ge 0$.
\end{lemma}

\begin{proof}
  %TODO
\end{proof}
\textbf{Remark.} Let $g(x):= cosh(\sqrt{x})$ where $cosh(x)$ is defined by $cosh(\sqrt{x})=\overunderset{\infty}{n=0}{\sum}\frac{x^n}{(2n)!}$, then: 
\begin{enumerate}
\item For all $x\geq 0$, we have $x \leq 2+cosh(\sqrt{x}) \leq 3e^{\sqrt{x}}$.
\item For all $x <0$, we have $-1 \leq cosh(\sqrt{x})\leq 1$. In particular, $2+cosh(x)\geq 1$ for all $x\in \mathbb{R}$.
\end{enumerate}
\begin{proof} To prove (1), let $x\geq 0$ then:
\begin{equation*}
  2+cosh(\sqrt{x}) = 3 + \overunderset{\infty}{n=1}{\sum}\frac{x^n}{(2n)!}\geq 3 + \frac{x}{2}+\frac{x^2}{24}.
\end{equation*}
However, \begin{equation*}
  3+\frac{x}{2}+\frac{x^2}{24}\geq x \iff \frac{1}{24}(x^2-12x+72)\geq 0 \iff \frac{1}{24}((x-6)^2+36)\geq 0,s
\end{equation*}
which concludes the lower bound in the first point. To conclude (1), we note the following for $x\geq0$: 
\begin{equation*}
3e^{\sqrt{x}}= 3\overunderset{\infty}{n=0}{\sum}\frac{x^{n/2}}{n!}\geq 3\overunderset{\infty}{n=0}{\sum}\frac{x^{n}}{(2n)!} \geq 2 + \overunderset{\infty}{n=0}{\sum}\frac{x^{n}}{(2n)!}= 2 + cosh(\sqrt{x}).
\end{equation*}
To prove (2), note that for $x<0$,
\begin{equation*}
cosh(\sqrt{x})= \overunderset{\infty}{n=0}{\sum}\frac{x^n}{(2n)!}= \overunderset{\infty}{n=0}{\sum}\frac{(-1)^n \sqrt{-x}^{2n}}{(2n)!}= cos(\sqrt{-x}).
\end{equation*}
(2) then follows by noting that $cos(\sqrt{-x}) \in [-1,1]$ for all $x<0$. 
\end{proof}
\begin{lemma}[Special-function lemma (Part 1 of Lemma 3.3 in Balister et al.)]
  \label{lem:special-function-e}
  \uses{def:f}
  \lean{specialFunctionE}
  Let $r \in \N$. If $x_i \ge - 3r$ for all $i \in [r]$, the function $f \colon \R^r \to \R$ defined in~\eqref{eq:f} satisfies 
  $$ f(x_1,\dots,x_r) \le 3^r r \exp\bigg( \displaystyle\sum_{i = 1}^r \sqrt{ x_i + 3r } \bigg)$$
\end{lemma}
\begin{proof} 
  \begin{equation*}
    f(x_1,\dots,x_r)= \Bigl(\overunderset{r}{i=1}{\prod}(2+cosh\sqrt{x_i})\Bigr)\overunderset{r}{j=1}{\sum}\frac{x_j}{2+cosh \sqrt{x_j}}
    \overset{*}{\leq} \Bigl(\overunderset{r}{i=1}{\prod}(2+cosh\sqrt{x_i +3r})\Bigr)\overunderset{r}{j=1}{\sum}1 \overset{**}{\leq}r\Bigl(\overunderset{r}{i=1}{\prod} 3e^{\sqrt{x_i+3r}}\Bigr),
  \end{equation*}
  Where (*) follows since $cosh(\sqrt{x})$ is increasing on the positive reals, that $cosh(x)\leq 1$ for negative $x$, and point (1) of the above remark.
  (**) follows from point (1) of the above remark.
\end{proof}


\begin{lemma}[Special-function lemma (Part 2 of Lemma 3.3 in Balister et al.)]
  \label{lem:special-function-ec}
  \uses{def:f}
  \lean{specialFunctionEc}
  Let $r \in \N$. If there exists an $i \in [r]$ with $x_i \le - 3r$, the function $f \colon \R^r \to \R$ defined in~\eqref{eq:f} satisfies
  $$
  f(x_1,\dots,x_r) \le -1$$
\end{lemma}

\begin{proof}
  Let $i \in [r]$ satisfy $x_i \leq -3r$. Note that if $x\geq 0$, then $\frac{x}{2+cosh(\sqrt{x})}\leq 1$ by point (1) of the above remark.
  Trivially, we have $\frac{x}{2+cosh{\sqrt{x}}}<0\leq 1$ for $x<0$ (note that $2+cosh(\sqrt{x})\geq 1$.)
  Therefore, we have 
  \begin{equation*}
  \underset{j \in [r], j \neq i}{\sum} \frac{x_j}{2+cosh(\sqrt{x_j})} \leq r-1.
  \end{equation*}
  On the other hand, we know that $\frac{x_i}{2+cosh(\sqrt{x_i})} \leq \frac{x_i}{3}$ by part (2) in the remark above and therefore,
\begin{equation*}
\overunderset{r}{j=1}{\sum}\frac{x_j}{2+cosh(\sqrt{x_j})}\leq \frac{x_i}{3}+r-1\leq -1.
\end{equation*}
Finally we write 
\begin{equation*}
  f(x_1,\dots,x_r) = \Bigl(\overunderset{r}{i=1}{\prod}(2+cosh\sqrt{x_i})\Bigr)\overunderset{r}{j=1}{\sum}\frac{x_j}{2+cosh \sqrt{x_j}} \leq -1,
\end{equation*}
since the sum in the last term is $\leq -1$ while the product is at least $1$ (each factor in the product is at least 1).
\end{proof}
\begin{lemma}[Geometric lemma (Lemma 3.1 in Balister et al.)]
  \label{lem:geometric}
  Let $r, n\in\N$. Set $\beta = 3^{-4r}$ and $C = 4r^{3/2}$.

  Let\/ $U$ and\/ $U'$ be i.i.d.~random variables taking values in a finite set~$X$, and let $\sigma_1,\ldots,\sigma_r \colon X \to \R^n$ be arbitrary functions. There exists $\lambda\ge-1$ and\/ $i\in[r]$ such that
  $$\Pr\Big( \big\langle \sigma_i(U),\sigma_i(U') \big\rangle \ge \lambda \, \text{ and } \, \big\langle \sigma_j(U), \sigma_j(U') \big\rangle \ge -1 \, \text{ for all } \, j \ne i \Big) \ge \beta e^{- C\sqrt{\lambda + 1}}.$$
\end{lemma}

\begin{proof}
  \uses{def:p, lem:special-function-e, lem:special-function-ec, lem:moments, def:f, lem:le-coshsqrt}
  For each $i \in [r]$, define $Z_i = 3r\big\langle \sigma_i(U),\sigma_i(U') \big\rangle$, and let $E$ be the event that $Z_i \ge -3r$ for every $i \in [r]$.

  Consider two cases:

  First assume $\Pr(E) \ge \beta$. Note that
  $$\Pr(E) = \Pr\Big( Z_i \ge - 3r \, \text{ for all } \, i \in [r] \Big),$$
  so with $\lambda = -1$,
  \begin{align*}
    \beta e^{-C\times 0} &= \beta\\
    &\le \Pr(E)\\
    &= \Pr\Big(3r\big\langle \sigma_i(U),\sigma_i(U') \big\rangle \ge -3r \text{ for all }i\Big)\\
    &= \Pr\Big( \big\langle \sigma_i(U),\sigma_i(U') \big\rangle \ge \lambda \, \text{ and } \, \big\langle \sigma_j(U), \sigma_j(U') \big\rangle \ge -1 \, \text{ for all } \, j \ne i \Big)
  \end{align*}
  hence the claimed inequality holds.

  Now, assume $\Pr(E) \le \beta$ and assume for the sake of a contradiction that for all $\lambda \geq -1$,

  \begin{align}\label{eq:max:big:and:E:no}
    \Pr\left(E \cap \left( \bigcup_{i \in [r]} \left\{ \big\langle \sigma_i(U),\sigma_i(U') \big\rangle \ge \lambda \right\}\right)\right) < \beta r e^{-C\sqrt{\lambda + 1}}.
  \end{align}

  Observe that, since $x \le 2 + \cosh\sqrt{x}$ (Lemma~\ref{lem:le-coshsqrt}) and using Lemma~\ref{lem:moments} and linearity of expectation,
  \[
    \Ex\big[ f\big( Z_1,\ldots,Z_r \big) \big] = \Ex\left[ \sum_{j = 1}^r Z_j \prod_{i \ne j} \left( 2 + \cosh(\sqrt{Z_i}) \right) \right]
    \ge \sum_{j = 1}^r \Ex\left[ \prod_{i \in [r]} Z_i \right] = \sum_{j = 1}^r (3r)^r \Ex\left[ \prod_{i \in [r]} \big\langle \sigma_i(U),\sigma_i(U') \big\rangle \right] \ge 0
  \]

  We hence have
  \begin{align*}
    0 &\le \Ex\big[ f\big( Z_1,\ldots,Z_r \big) \big]\\
    &= \Ex\big[ f\big( Z_1,\ldots,Z_r \big)  \mathbf{1}_E \big] + \Ex\big[ f\big( Z_1,\ldots,Z_r \big) \mathbf{1}_{E^c} \big]\\
    &\le \Ex\left[ 3^r r \exp\bigg( \displaystyle\sum_{i = 1}^r \sqrt{ Z_i + 3r } \bigg)  \mathbf{1}_E \right] + \Ex\big[-1 \cdot \mathbf{1}_{E^c} \big]
  \end{align*}
  where we use Lemma~\ref{lem:special-function-e} to bound the case for $E$, and Lemma~\ref{lem:special-function-ec} for $E^c$.
  It follows that
  \begin{equation}\label{eq:eventE:inequality}
    1 - \Pr(E) \le 3^r r \cdot \Ex\bigg[ \exp\bigg( \sum_{i = 1}^r \sqrt{ Z_i + 3r } \bigg) \mathbf{1}_E \bigg].
  \end{equation}

  Let $M = \max \big\{ \big\langle \sigma_i(U),\sigma_i(U') \big\rangle : i \in [r] \big\}$. For any constant $c \le C - 1$, we have
  \begin{align}
  \exp(c\sqrt{M+1})\id_E&= \id_E \Bigl(e^{c\sqrt{1-1}}+ \int_{-1}^M \frac{ce^{c\sqrt{\lambda+1}}}{2\sqrt{\lambda+1}} d\lambda\Bigr)\\
  &= \id_E+ \int_{-1}^{\infty} \id_{E,\{M\geq \lambda\}}\frac{ce^{c\sqrt{\lambda+1}}}{2\sqrt{\lambda+1}} d\lambda.
  \end{align}
  Given any $c \leq C-1$ we take the expected value of both sides of the previous equation and apply Tonelli's theorem to obtain:
  \begin{align*}
    \Ex\Big[ \exp\big( c \sqrt{M + 1} \big) \mathbf{1}_E \Big]
    & % = \int_{E} \exp\big( c \sqrt{M + 1}  \big) d\Pr
    \\
    & \le \, \Pr(E) + \int_{-1}^\infty \Pr\Big( \big\{ M \ge \lambda \big\} \cap E \Big) \cdot \frac{c}{2\sqrt{\lambda + 1}} \cdot e^{c \sqrt{\lambda + 1}} \,\mathrm{d}\lambda\\ %TODO not clear!
    & \le \, \beta +  \int_{-1}^\infty \frac{\beta r c}{2\sqrt{\lambda + 1}} \cdot e^{- C\sqrt{\lambda + 1}+c\sqrt{\lambda+1}} \,\mathrm{d}\lambda\\
    & \le \, \beta + \beta r \int_{-1}^\infty \frac{c}{2\sqrt{\lambda + 1}} \cdot e^{- \sqrt{\lambda + 1}} \,\mathrm{d}\lambda\\
    & \le \, \beta (cr + 1),
  \end{align*}
 where in the second inequality we used (\ref{eq:max:big:and:E:no}) and $\Pr(E) \le \beta$; in the third we used $c \le C - 1$; and in the last inequality we used the fact that $\int_0^\infty \frac{1}{2\sqrt{x}} e^{-\sqrt{x}} \, \mathrm{d}x = 1$.
 Note that the second and third inequalities rely on the non-negativity of the integrand.
  In particular, applying this with $c = \sqrt{3}r^{3/2}$, and recalling that $C = 4r^{3/2} \ge c + 1$ and $\beta = 3^{-4r}$, it follows that
  \begin{align}
    1 - \Pr(E) &\le 3^r r \cdot \Ex\bigg[ \exp\bigg( \sum_{i = 1}^r \sqrt{ Z_i + 3r } \bigg) \mathbf{1}_E \bigg]\\
    &\le  3^r r \cdot \Ex\bigg[ \exp\bigg( r \cdot \max_{i \in [r]} \sqrt{ Z_i + 3r } \bigg) \mathbf{1}_E \bigg]\\
    &= 3^r r \cdot \Ex\bigg[ \exp\bigg( r \cdot \sqrt{ 3r} \cdot \sqrt{ (M + 1) } \bigg) \mathbf{1}_E \bigg]\\
    &\le 3^r r \cdot \beta (r^{2}\sqrt{3r} + 1) \le 1/3,
  \end{align}
  which contradicts our assumption that $\Pr(E) \le \beta$.

  Hence, there exists $\lambda \ge -1$ such that
  \begin{align}\label{eq:max:big:and:E}
    \beta r e^{-C\sqrt{\lambda + 1}} &\le \Pr\left(E \cap \left( \bigcup_{i \in [r]} \left\{ \big\langle \sigma_i(U),\sigma_i(U') \big\rangle \ge \lambda \right\}\right)   \right) \\
    &\le \sum_{i \in [r]} \Pr\left(E \cap \left\{ \big\langle \sigma_i(U),\sigma_i(U') \big\rangle \ge \lambda \right\} \right)\\
    &\le r \cdot \max_{i \in [r]} \Pr\left(E \cap \left\{ \big\langle \sigma_i(U),\sigma_i(U') \big\rangle \ge \lambda \right\} \right) ,
  \end{align}
  and therefore there exists an $i \in [r]$ as required.

\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Book Theorem}


\begin{lemma}[Key lemma (Lemma 2.2 in Balister et al.)]
  \label{lem:key-lemma}
  \uses{def:p}

  Let $r, n\in\N$. Set $\beta = 3^{-4r}$ and $C = 4r^{3/2}$.

  Let\/ $\chi$ be an\/ $r$-colouring of\/ $E(K_n)$, let\/ $X,Y_1,\ldots,Y_r \subset V(K_n)$ be non-empty sets of vertices, and let $\alpha_1,\ldots,\alpha_r > 0$. There exists a vertex $x \in X$, a colour $\ell \in [r]$, sets $X' \subset X$ and\/ $Y'_1,\ldots,Y'_r\,$ with\/ $Y'_i \subset N_i(x) \cap Y_i\,$ for each $i \in [r]$, and\/ $\lambda \ge -1$, such that
  \begin{equation}\label{eq:key:ell}
    \beta e^{- C \sqrt{\lambda + 1}} |X| \le |X'| \qquad \text{and} \qquad p_\ell(X,Y_\ell) + \lambda \alpha_\ell \le p_\ell( X', Y'_\ell ) ,
  \end{equation}
  and moreover
  \begin{equation}\label{eq:key:alli}
    |Y'_i| = p_i(X,Y_i) |Y_i| \qquad \text{and} \qquad  p_i(X,Y_i) - \alpha_i \le p_i( X', Y'_i )
  \end{equation}
  for every $i \in [r]$.
\end{lemma}

\begin{proof}
  \uses{def:p, lem:geometric}

  For each colour $i \in [r]$, define a function $\sigma_i \colon X \to \R^{\cup_i Y_i}$ as follows: for each $x \in X$, choose a set $N'_i(x) \subset N_i(x) \cap Y_i$ of size exactly $p_i|Y_i|$, where $p_i = p_i(X,Y_i)$, and set
  $$\sigma_i(x) = \frac{\id_{N'_i(x)} - p_i\id_{Y_i}}{\sqrt{\alpha_ip_i|Y_i|}},$$
  where $\id_S \in \{0,1\}^{\cup_i Y_i}$ denotes the indicator function of the set $S$. Note that, for any $x,y\in X$,
   %TODO why? mp direction suffices
  $$\lambda \le \big\langle \sigma_i(x),\sigma_i(y) \big\rangle \quad \Leftrightarrow \quad \big( p_i + \lambda\alpha_i \big) p_i |Y_i| \le |N'_i(x) \cap N'_i(y)|.$$
  Indeed, for every $x,y\in X$, we have 
  \begin{multline}
    \begin{aligned}
            \alpha_ip_i|Y_i| \langle \sigma_i(x),\sigma_i(y) \rangle &= \langle \id_{N'_i(x)}- p_i\id_{Y_i},\id_{N'_i(y)}- p_i\id_{Y_i}\rangle\\
            &= \Bigl(\big\langle \id_{N'_i(x)},\id_{N'_i(y)}\big\rangle +p_i^2\langle \id_{Y_i},
            \id_{Y_i}\rangle - p_i \langle \id_{N'_i(x)},\id_{Y_i}\rangle- p_i \langle \id_{N'_i(y)},\id_{Y_i}\rangle\Bigr)\\
            &= \Bigl(|N'_i(x) \cap N'_i(y)|-p_i^2|Y_i| \Bigr),
    \end{aligned}
  \end{multline}
  Where the last ineqaulity follows since $|N'_i(x)|= N'_i(y)|= p_i|Y_i|$ and both sets are subsets of $Y_i$.
  Now, by Lemma~\ref{lem:geometric}, there exists $\lambda \ge -1$ and colour $\ell \in [r]$ such that
  \begin{equation}
    \label{eq: geometric-app}
    \beta e^{- C\sqrt{\lambda + 1}} \le \Pr\Big( \lambda  \le \big\langle \sigma_\ell(U),\sigma_\ell(U') \big\rangle \, \text{ and } \, -1 \le \big\langle \sigma_i(U), \sigma_i(U') \big\rangle \, \text{ for all } \, i \ne \ell \Big) .
  \end{equation}

  where $U$, $U'$ are independent random variables distributed uniformly in the set~$X$. We claim that there exists a vertex $x \in X$ and a set $X' \subset X$
   %TODO
  such that,
  $$\beta e^{- C \sqrt{\lambda + 1}} |X| \le |X'|$$ %TODO why?
  and
  $$\big( p_\ell + \lambda\alpha_\ell \big) p_\ell |Y_\ell | \le |N'_\ell(x) \cap N'_\ell(y)|$$
  for every $y \in X'$, and
  $$\big( p_i - \alpha_i \big) p_i |Y_i| \le |N'_i(x) \cap N'_i(y)|$$
  for every $y \in X'$ and $i \in [r]$. To see this, we let 
  $$ P= \Biggl\{(x,x'): x,x' \in X , \lambda  \le \big\langle \sigma_\ell(x),\sigma_\ell(x') \big\rangle \, \text{ and } \, -1 \le \big\langle \sigma_i(x), \sigma_i(x') \big\rangle \, \text{ for all } \, i \ne \ell  \Biggr\}.$$
  Since $U$ and $U'$ are independent and uniformly distributed over $x$, Equation \ref{eq: geometric-app} implies that
  \begin{equation}
  |P|\geq \beta e^{-C\sqrt{\lambda + 1}}|X|^2.
  \end{equation} 
  However, by averaging, there must then exist a vertex $x \in X$ such that:
  \begin{equation}
|X'|:=\bigl|\{y: (x,y) \in P  \} \bigr| \ge \frac{\beta e^{-C\sqrt{\lambda+1}}|X|^2}{|X|}\geq  \beta e^{-C\sqrt{\lambda+1}}|X|.
  \end{equation}
  We can them simply pick this $X'$ to be the desired subset.
  Setting $Y'_i = N'_i(x)$ for each $i \in [r]$, it follows that
  \begin{multline}
      \begin{aligned}
      p_\ell(X,Y_\ell) + \lambda \alpha_\ell &= \frac{ \big( p_\ell + \lambda\alpha_\ell \big) p_\ell |Y_\ell |}{p_\ell |Y_\ell|}\\
      &= \frac{ \big( p_\ell + \lambda\alpha_\ell \big) p_\ell |Y_\ell |}{| N'_\ell (x)|}\\
      &= \min\bigg\{ \frac{ \big( p_\ell + \lambda\alpha_\ell \big) p_\ell |Y_\ell |}{| N'_\ell (x)|} : x' \in X' \bigg\}\\
      &\le \min\bigg\{ \frac{|N'_\ell(x') \cap  N'_\ell (x)|}{| N'_\ell (x)|} : x' \in X' \bigg\}\\
      &= \min\bigg\{ \frac{|N_\ell(x') \cap  N'_\ell (x)|}{| N'_\ell (x)|} : x' \in X' \bigg\}\\
      &= p_\ell\big( X', N'_\ell (x) \big) = p_\ell\big( X', Y'_\ell \big) \\
    \end{aligned}
  \end{multline}

  and $$  p_i(X,Y_i) - \alpha_i \le \qquad p_i\big( X', Y'_i \big) $$
  for every $i \in [r]$, as required.
\end{proof}


\begin{algorithm}[The Multicolour Book Algorithm in Balister et al.]\label{alg:book}
  %Let $\chi$ be an $r$-colouring of $E(K_n)$, let $X$ and $Y_1,\ldots, Y_r$ be disjoint sets of vertices of $K_n$, and 
  Set $T_1 = \cdots = T_r = \emptyset$, and repeat the following steps until either $X = \emptyset$ or $\max\big\{ |T_i| : i \in [r] \big\} = t$. 
  \begin{enumerate}
  \item\label{Alg:Step1} Applying the key lemma: let the vertex $x \in X$, the colour $\ell \in [r]$, the sets $X' \subset X$ and $Y'_1,\ldots,Y'_r$, and $\lambda \ge -1$ be given by Lemma~\ref{key:lemma}, applied with
  \begin{equation}\label{def:alpha}
  \alpha_i = \frac{p_i(X,Y_i) - p_0 + \delta}{t}
  \end{equation}
  for each $i \in [r]$, and go to Step~2.\smallskip
  \item\label{Alg:Step2} Colour step: If $\lambda \le \lambda_0$, then choose a colour $j \in [r]$ such that the set
  $$X'' = N_j(x) \cap X'$$ 
  has at least $(|X'| - 1)/r$ elements, and update the sets as follows:
  $$X \to X'', \qquad Y_j \to Y'_j \qquad \text{and} \qquad T_j \to T_j \cup \{x\}$$
  and go to Step~1. Otherwise go to Step~3.\smallskip
  \item\label{Alg:Step3} Density-boost step: If $\lambda > \lambda_0$, then we update the sets as follows:
  $$X \to X' \qquad \text{and} \qquad Y_\ell \to Y'_\ell,$$
  and go to Step~1.
  \end{enumerate}  
\end{algorithm} 

\begin{lemma}[Lemma 4.1 in Balister et al.]\label{lem:pi:lower:bound}
  \uses{alg:book}
  For each $i \in [r]$ and $s \in \N$, 
  \begin{equation}\label{eq:pi:lower:bound}
    p_i(s) - p_0 + \delta \, \ge \, \delta \cdot \bigg( 1 - \frac{1}{t} \bigg)^{t} \prod_{j \in \cB_i(s)} \bigg( 1 + \frac{\lambda(j)}{t} \bigg).
  \end{equation}
\end{lemma}
  
\begin{proof}
  \uses{lem:key-lemma}
  Note first that if $Y_i(s+1) = Y_i(s)$, then $p_i(s+1) \ge p_i(s)$, since the minimum degree does not decrease when we take a subset of $X(s)$. When we perform a colour step in colour $i$, % (that is, we add $x$ to $T_i$), 
  we have $p_i(s+1) \ge p_i(s) - \alpha_i(s)$, by Lemma~\ref{key:lemma}, and hence
  $$p_i(s+1) - p_0 + \delta \ge \bigg( 1 - \frac{1}{t} \bigg) \big( p_i(s) - p_0 + \delta \big),$$
  by our choice of $\alpha_i(s)$. Similarly, when we perform a density-boost step in colour $i$  
  we have $p_i(s+1) \ge p_i(s) + \lambda(s) \alpha_i(s)$, by Lemma~\ref{key:lemma}, and hence
  $$p_i(s+1) - p_0 + \delta \ge \bigg( 1 + \frac{\lambda(s)}{t} \bigg) \big( p_i(s) - p_0 + \delta \big).$$
  Recalling that there are at most $t$ colour steps in colour $i$, and that $p_i(0) \ge p_0$, by the definition~\eqref{def:p0} of $p_0$, the claimed bound follows. 
\end{proof}

Before continuing, let's note a couple of important consequences of Lemma~\ref{lem:pi:lower:bound}. First, it implies that neither $p_i(s)$ nor $\alpha_i(s)$ can get too small. 

\begin{lemma}[Lemma 4.2 in Balister et al.]\label{lem:pi:min} 
  \uses{alg:book}
  If\/ $t \ge 2$, then 
  $$p_i(s) \, \ge \, p_0 - \frac{3\delta}{4} \qquad \text{and} \qquad \alpha_i(s) \, \ge \, \frac{\delta}{4t}$$
  for every $i \in [r]$ and $s \in \N$. 
\end{lemma}

\begin{proof}
  \uses{lem:pi:lower:bound}
  Both bounds follow immediately from~\eqref{eq:pi:lower:bound} and the definition of $\alpha_i(s)$. 
\end{proof}
  
It also implies the following bound on the number of density-boost steps. 

\begin{lemma}[Lemma 4.3 in Balister et al.]\label{lem:Bi:max}
  \uses{alg:book}
  If\/ $t \ge \lambda_0$ and\/ $\delta \le 1/4$, then
  $$|\cB_i(s)| \le \frac{4 \log(1/\delta)}{\lambda_0} \cdot t$$
  for every $i \in [r]$ and $s \in \N$. 
\end{lemma}
  
\begin{proof}
    \uses{lem:pi:lower:bound}
  Since $\lambda(j) > \lambda_0$ for every $j \in \cB_i(s)$, and $p_i(s) \le 1$, it follows from~\eqref{eq:pi:lower:bound} that
  $$\frac{\delta}{4} \bigg( 1 + \frac{\lambda_0}{t} \bigg)^{|\cB_i(s)|} \le 1 + \delta.$$
  Since $t \ge \lambda_0$ and $\delta \le 1/4$, the claimed bound follows. 
\end{proof}

Lemmas~\ref{lem:pi:min} and~\ref{lem:Bi:max} together provide a lower bound on the size of the set $Y_i(s)$. 

\begin{lemma}[Lemma 4.4 in Balister et al.]\label{lem:Y:lower:bound}
  \uses{alg:book}
  If\/ $t \ge 2$, then
  $$|Y_i(s)| \ge \bigg( p_0 - \frac{3\delta}{4} \bigg)^{t + |\cB_i(s)|} |Y_i(0)|$$
  for every $i \in [r]$ and $s \in \N$. 
\end{lemma}
  
\begin{proof}
  \uses{lem:pi:min, lem:Bi:max}
  Note that $Y_i(j+1) \ne Y_i(j)$ for at most $t + |\cB_i(s)|$ of the first $s$ steps, and for those steps we have
  $$|Y_i(j+1)| = p_i(j) |Y_i(j)| \ge \bigg( p_0 - \frac{3\delta}{4} \bigg) |Y_i(j)|,$$ 
  by~\eqref{eq:key:alli} and Lemma~\ref{lem:pi:min}.
\end{proof}


Finally, we need to bound the size of the set $X(s)$. To do so, set $\eps = (\beta / r) e^{- C \sqrt{\lambda_0 + 1}}$, and define $\cB(s) = \cB_1(s) \cup \cdots \cup \cB_r(s)$ to be the set of all density-boost steps. 

\begin{lemma}[Lemma 4.5 in Balister et al.]\label{lem:X:lower:bound}
  \uses{alg:book}
  For each $s \in \N$, 
  \begin{equation}\label{eq:X:lower:bound}
  |X(s)| \ge \eps^{rt + |\cB(s)|} \exp\bigg( - C \sum_{j \in \cB(s)} \sqrt{\lambda(j)+1}\,\, \bigg) |X(0)| - rt.
  \end{equation}
\end{lemma}

\begin{proof}
  If $\lambda(j) \le \lambda_0$, then by~\eqref{eq:key:ell} and Step~2 of the algorithm we have
  $$|X(j+1)| \ge \frac{\beta e^{- C \sqrt{\lambda_0 + 1}}}{r} \cdot |X(j)| - 1 = \eps |X(j)| - 1.$$ 
  On the other hand, if $\lambda(j) > \lambda_0$, then $j \in \cB(s)$, and we have 
  $$|X(j+1)| \ge \beta e^{- C \sqrt{\lambda(j) + 1}} |X(j)|,$$ 
  by~\eqref{eq:key:ell} and Step~3 of the algorithm. Since there are at most $rt$ colour steps, and $\beta \ge \eps$, the claimed bound follows.
\end{proof}

We will use the following lemma to bound the right-hand side of~\eqref{eq:X:lower:bound}. 

\begin{lemma}[Lemma 4.6 in Balister et al.]\label{lem:sum:of:lambdas}
  \uses{alg:book}
  If\/ $t \ge \lambda_0 / \delta > 0$ and\/ $\delta \le 1/4$, then
  $$\sum_{j \in \cB(s)} \sqrt{\lambda(j)} \le \frac{7r \log(1/\delta)}{\sqrt{\lambda_0}} \cdot t$$
  for every $s \in \N$. 
\end{lemma}

\begin{proof}
  Observe first that, by Lemma~\ref{lem:pi:lower:bound}, we have 
  \begin{equation}\label{eq:B:condition}
  \frac{\delta}{4} \prod_{j \in \cB_i(s)} \bigg( 1 + \frac{\lambda(j)}{t} \bigg) \le 1 + \delta
  \end{equation}
  for each $i \in [r]$. Note also that $\lambda_0 \le \lambda(j) \le 5t/\delta$ for every $j \in \cB(s)$, where the lower bound holds by the definition of $\cB(s)$, and the upper bound by~\eqref{eq:B:condition} and since $\delta \le 1/4$. Now, since $\log(1+x) \ge \min\{ x/2,1\}$ for all $x > 0$, it follows that
  %the function $\sqrt{x}/\log(1+x)$ is increasing either side of its unique minimum, and therefore %is therefore maximised at one of its extreme points. 
  \begin{equation}\label{eq:not:convexity}
  \frac{ \sqrt{\lambda(j)} }{\log(1 + \lambda(j)/t) } \le \max\bigg\{ \frac{ 2t }{ \sqrt{\lambda_0} }, \, \sqrt{ \frac{5t}{\delta}} \bigg\} \le \frac{ 3t }{ \sqrt{\lambda_0} },
  %\frac{ \sqrt{\lambda(j)} }{\log(1 + \lambda(j)/t) } \le \max\bigg\{ \frac{ \sqrt{\lambda_0} }{ \log(1 + \lambda_0/t) }, \, \frac{\sqrt{5t/\delta}}{\log(1 + 5/\delta)} \bigg\} \le \frac{ 2t }{ \sqrt{\lambda_0} },
  \end{equation}
  where in the second inequality we used %the fact that $\log(1 + x) \ge x/2$ for all $0 < x \le 1/4$, and 
  our assumption that $t \ge \lambda_0 / \delta$. It now follows that
  $$\sum_{j \in \cB_i(s)} \sqrt{\lambda(j)} \le \frac{ 3t }{ \sqrt{\lambda_0} } \sum_{j \in \cB_i(s)} \log \bigg( 1 + \frac{\lambda(j)}{t} \bigg) \le \frac{7 \log(1/\delta)}{\sqrt{\lambda_0}} \cdot t,$$
  where the first inequality holds by~\eqref{eq:not:convexity}, and the second follows from~\eqref{eq:B:condition}, since $\delta \le 1/4$. Summing over $i \in [r]$, we obtain the claimed bound. 
\end{proof}


\begin{theorem}\label{thm:book}
  Let\/ $\chi$ be an\/ $r$-colouring of\/ $E(K_n)$, and let\/ $X,Y_1,\ldots,Y_r \subset V(K_n)$. % be disjoint sets. 
  For every $p > 0$ and $\mu \ge 2^{10} r^3$, and every $t,m \in \N$ with $t \ge \mu^5 / p$, the following holds. If 
  $$|N_i(x) \cap Y_i| \ge p|Y_i|$$
  for every $x \in X$ and $i \in [r]$, and moreover
  $$|X| \ge \bigg( \frac{\mu^2}{p} \bigg)^{\mu r t} \qquad \text{and} \qquad |Y_i| \ge \bigg( \frac{e^{2^{13} r^3 / \mu^2}}{p} \bigg)^t \, m,$$ 
  then $\chi$ contains a monochromatic $(t,m)$-book.
\end{theorem}

\begin{proof}
  \uses{lem:Bi:max, lem:Y:lower:bound, lem:sum:of:lambdas, lem:X:lower:bound, alg:book}
  Recall that we are given an $r$-colouring $\chi$ of $E(K_n)$ and a collection of %disjoint 
  sets $X,Y_1,\ldots,Y_r \subset V(K_n)$ with
  \begin{equation}\label{eq:book:thm:conditions}
  |X| \ge \bigg( \frac{\mu^2}{p} \bigg)^{\mu r t} \qquad \text{and} \qquad |Y_i| \ge \bigg( \frac{e^{2^{13} r^3 / \mu^2}}{p} \bigg)^t \, m
  \end{equation}
  for each $i \in [r]$, for some $p > 0$, $\mu \ge 2^{10} r^3$ and $t,m \in \N$ with $t \ge \mu^5 / p$, and moreover
  \begin{equation}\label{eq:book:thm:min:degree}
  |N_i(x) \cap Y_i| \ge p|Y_i|
  \end{equation}
  for every $x \in X$ and $i \in [r]$. 
  %Our task is to show that the multicolour book algorithm produces a monochromatic $(t,m)$-book. 
  We will run the multicolour book algorithm with
  $$\delta = \frac{p}{\mu^2} \qquad \text{and} \qquad \lambda_0 = \bigg( \frac{\mu \log(1/\delta)}{8C} \bigg)^2,$$
  where $C = 4r^{3/2}$ (as before), and show that it ends with
  $$\max \big\{ |T_i(s)| : i \in [r] \big\} = t \qquad \text{and} \qquad \min\big\{ |Y_i(s)| : i \in [r] \big\} \ge m,$$
  and therefore produces a monochromatic $(t,m)$-book.
  
  To do so, we just need to bound the sizes of the sets $X(s)$ and $Y_i(s)$ from below. Observe that $t \ge \lambda_0$ and $\delta \le 1/4$, and therefore, by Lemma~\ref{lem:Bi:max}, that
  \begin{equation}\label{eq:Bi:final:bound}
  |\cB_i(s)| \, \le \, \frac{4 \log(1/\delta)}{\lambda_0} \cdot t \, = \, \frac{2^{12} r^3}{\mu^2 \log(1/\delta)} \cdot t \, \le \, t
  \end{equation}
  for every $i \in [r]$ and $s \in \N$. Since $p_0 \ge p$, by~\eqref{eq:book:thm:min:degree} and the definition of $p_0$, it follows that  
  $$|Y_i(s)| \, \ge \, \bigg( p - \frac{3\delta}{4} \bigg)^{t + |\cB_i(s)|} |Y_i| \, \ge \, e^{-2\delta t / p} \, p^{|\cB_i(s)|} \, \big( e^{2^{13} r^3 / \mu^2} \big)^t \, m,$$
  where the first inequality holds by Lemma~\ref{lem:Y:lower:bound}, and the second by~\eqref{eq:book:thm:conditions} and~\eqref{eq:Bi:final:bound}. Noting that $p^{|\cB_i(s)|} \ge e^{-2^{12} r^3 t / \mu^2}$, by~\eqref{eq:Bi:final:bound}, and that $\delta / p = 1/\mu^2$, it follows that 
  $$|Y_i(s)| \, \ge \, e^{-2 t / \mu^2} \big( e^{2^{12} r^3 / \mu^2} \big)^t \, m \, \ge \, m,$$
  as claimed. To bound $|X(s)|$, recall~\eqref{eq:X:lower:bound} and observe that 
  $$\eps^{rt + |\cB(s)|}  \ge \bigg( \frac{\beta}{r} \cdot e^{- C \sqrt{\lambda_0 + 1}} \bigg)^{2rt} \ge \big( e^{- 4C \sqrt{\lambda_0}} \big)^{rt} = \delta^{\mu r t/2} = \bigg( \frac{\mu^2}{p} \bigg)^{-\mu r t / 2},$$
  where the first step holds because $\eps = (\beta / r) e^{- C \sqrt{\lambda_0 + 1}}$ and $|\cB(s)| \le rt$, by~\eqref{eq:Bi:final:bound}, and the second step holds because $\beta = 3^{-4r}$ and $\lambda_0 \ge 2^{10} r^3$. Moreover, we have
  $$\sum_{j \in \cB(s)} \sqrt{\lambda(j)+1} \le \frac{8r \log(1/\delta)}{\sqrt{\lambda_0}} \cdot t = \frac{2^6Crt}{\mu},$$
  by Lemma~\ref{lem:sum:of:lambdas} and our choice of $\lambda_0$, and therefore 
  $$|X(s)| \ge \bigg( \frac{\mu^2}{p} \bigg)^{\mu r t / 2} \exp\bigg( - \frac{2^6C^2rt}{\mu} \bigg) - rt > 0,$$
  for every $s \in \N$, by Lemma~\ref{lem:X:lower:bound} and since $\mu \ge 2^{10} r^3$ and $C = 4r^{3/2}$. It follows that the algorithm produces a monochromatic $(t,m)$-book, as claimed. 
\end{proof}
  



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Deducing the Bound on the Ramsey Number}


\begin{lemma}[Lemma 5.2 in Balister et al.]\label{lem:ESz:steps}
  Given\/ $n,r \in \N$ and\/ $\eps > 0$, and an $r$-colouring of $E(K_n)$, the following holds. There exist disjoint sets of vertices\/ $S_1,\dots,S_r$ and\/ $W$ such that, for every $i \in [r]$, 
  $$|W| \ge \bigg( \frac{1+\eps}{r} \bigg)^{\sum_{j = 1}^r |S_j|} n \qquad \text{and} \qquad |N_i(w) \cap W| \ge \bigg( \frac{1}{r} - \eps \bigg) |W| - 1$$ 
  for every $w \in W$, and $(S_i,W)$ is a monochromatic book in colour~$i$.
\end{lemma}

\begin{proof}
  We use induction on~$n$. Note that if $n \le r$ or $r = 1$, then the sets $S_1 = \cdots = S_r = \emptyset$ and $W = V(K_n)$ have the required properties. We may therefore assume that $n > r \ge 2$, and that there exists a vertex $x \in V(K_n)$ and a colour $\ell \in [r]$ such that
  $$|N_\ell(x)| < \bigg( \frac{1}{r} - \eps \bigg) n - 1,$$
  and hence there exists a different colour $j \ne \ell$ such that 
  $$|N_j(x)| \ge \frac{1}{r-1} \bigg( n - \bigg( \frac{1}{r} - \eps \bigg) n \bigg) \ge \bigg( \frac{1 + \eps}{r} \bigg) n.$$
  Applying the induction hypothesis to the colouring induced by the set $N_j(x)$, we obtain sets $S'_1,\ldots,S'_r$ and $W'$ satisfying the conclusion of the lemma with $n$ replaced by $|N_j(x)|$. Setting 
  $$W = W', \qquad S_j = S'_j \cup \{x\} \qquad \text{and} \qquad S_i = S'_i \qquad \text{for each } \, i \ne j,$$ 
  we see that $W$ satisfies the minimum degree condition (by the induction hypothesis), and
  $$|W| \ge \bigg( \frac{1+\eps}{r} \bigg)^{\sum_{i = 1}^r |S'_i|}|N_j(x)| \ge \bigg( \frac{1+\eps}{r} \bigg)^{\sum_{i=1}^r |S_i|}n.$$
  Since $(S_i,W)$ is a monochromatic book in colour~$i$ for each $i \in [r]$, it follows that $S_1,\dots,S_r$ and $W$ are sets with the claimed properties.
\end{proof}

\begin{lemma}[Lemma 5.3 in Balister et al.]\label{lem:many:ESz:steps}
  Let\/ $k,r \ge 2$ and\/ $\eps \in (0,1)$. We have 
  $$R_r\big( k - s_1, \ldots, k - s_r \big) \le e^{-\eps^3 k / 2} \bigg( \frac{1+\eps}{r} \bigg)^s r^{rk}$$
  for every $s_1,\ldots,s_r \in [k]$ with\/ $s = s_1 + \cdots + s_r \ge \eps^2 k$.
\end{lemma}
  
\begin{proof}
  By the Erd\H{o}s--Szekeres bound, we have
  $$R_r\big( k - s_1, \ldots, k - s_r \big) \le r^{rk - s}.$$
  The claimed bound follows, since $( 1 + \eps )^{\eps^2 k} \ge e^{\eps^3 k/2}$ for every $\eps \in (0,1)$.
\end{proof}

\begin{theorem}[Theorem 5.1 in Balister et al.] \label{thm:Ramsey:multicolour:quant}
  Let $r \ge 2$, and set $\delta = 2^{-160} r^{-12}$. Then
  %
  \begin{equation*}
    R_r(k) \le e^{-\delta k} r^{rk}
  \end{equation*}
  %
  for every $k \in \N$ with $k \ge 2^{160} r^{16}$. 
  \uses{def:R}
\end{theorem}

\begin{proof}
  \uses{lem:ESz:steps, lem:many:ESz:steps, thm:book, lem:multibounds}
  Given $r \ge 2$, set $\delta = 2^{-160} r^{-12}$, let $k \ge 2^{160} r^{16}$ and $n \ge e^{-\delta k} r^{rk}$, and let $\chi$ be an arbitrary $r$-colouring of $E(K_n)$. Set $\eps = 2^{-50} r^{-4}$, and let $S_1,\ldots,S_r$ and $W$ be the sets given by Lemma~\ref{lem:ESz:steps}. Suppose first that $|S_1| + \cdots + |S_r| \ge \eps^2 k$, and observe that, by Lemma~\ref{lem:many:ESz:steps} and our lower bounds on $n$ and $|W|$, we have 
  $$|W| \ge \bigg( \frac{1+\eps}{r} \bigg)^{\sum_{j = 1}^r |S_j|} e^{-\delta k} r^{rk} \ge R_r\big( k - |S_1|, \ldots, k - |S_r| \big).$$ 
  Since $(S_i,W)$ is a monochromatic book in colour~$i$ for each $i \in [r]$, it follows that there exists a monochromatic copy of $K_k$ in $\chi$, as required.
  
  We may therefore assume from now on that  $|S_1| + \cdots + |S_r| \le \eps^2 k$. 
  %Apply Lemma~\ref{lem:random:partition} to the colouring restricted to the set $W$, let $X$ and $Y_1,\ldots,Y_r$ be the sets given by the lemma 
  In this case we set $X = Y_1 = \cdots = Y_r = W$, and apply Theorem~\ref{thm:book} to the colouring restricted to $W$ with 
  $$p = \frac{1}{r} - 2\eps, \qquad \mu = 2^{30} r^3, \qquad t = 2^{-40} r^{-3} k \qquad \text{and} \qquad m = R\big( k, \ldots, k, k - t \big).$$
  In order to apply Theorem~\ref{thm:book}, we need to check that $t \ge \mu^5/p$, and that
  $$|X| \ge \bigg( \frac{\mu^2}{p} \bigg)^{\mu r t} \qquad \text{and} \qquad |Y_i| \ge \bigg( \frac{e^{2^{13} r^3 / \mu^2}}{p} \bigg)^t \, m.$$
  The first two of these inequalities are both easy: the first holds because $k \ge 2^{160} r^{16}$, and for the second note that since $n \ge r^{rk/2}$ and $\sum_{j = 1}^r |S_j| \le rk/4$, we have
  $$|X| \ge \bigg( \frac{1+\eps}{r} \bigg)^{rk/4} r^{rk/2} \ge r^{rk/4} \ge \big( 2^{61} r^7 \big)^{2^{-10} r k} \ge \bigg( \frac{\mu^2}{p} \bigg)^{\mu r t},$$
  as required. The third inequality is more delicate: observe first that 
  $$R\big( k, \ldots, k, k-t \big) \le \binom{rk-t}{k,\dots,k,k-t} \le e^{-(r-1)t^2/3rk} r^{rk-t} \le e^{-t^2/6k} r^{rk-t}.$$
  and therefore, since $\delta \le 2^{-10} t^2/k^2$ and $p = 1/r - 2\eps \ge e^{-3\eps r} / r$, we have 
  $$n \ge e^{-\delta k} r^{rk} \ge r^t e^{t^2/8k} \cdot R\big( k, \ldots, k, k-t \big) \ge \frac{m}{p^t} \cdot \exp\bigg( \frac{t^2}{8k} - 3\eps r t \bigg).$$
  Moreover, by our choice of $t$ and $\mu$, we have 
  $$\frac{t}{8k} = \frac{1}{2^{43} r^3} \ge \frac{1}{2^{47}r^3} + \frac{1}{2^{48}r^3} = \frac{2^{13} r^3}{\mu^2} + 4\eps r.$$
  Finally, since $\sum_{j = 1}^r |S_j| \le \eps^2 k \le \eps t$, it follows that
  $$|Y_i| = |W| \ge \bigg( \frac{1+\eps}{r} \bigg)^{\eps t} n \ge \frac{m}{p^t} \cdot \exp\bigg( \frac{t^2}{8k} - 4\eps r t \bigg) \ge \bigg( \frac{e^{2^{13} r^3 / \mu^2}}{p} \bigg)^t \, m,$$
  %$$|Y_i| \ge \frac{|W|}{4r} \ge \bigg( \frac{1+\eps}{r} \bigg)^{\eps^2 k} \frac{n}{4r} \ge \frac{m}{p^t} \cdot \exp\bigg( \frac{t^2}{8k} - 4\eps r t \bigg) \ge \bigg( \frac{e^{2^{13} r^3 / \mu^2}}{p} \bigg)^t \, m,$$
  as claimed. Thus $\chi$ contains a monochromatic $(t,m)$-book, and hence, by our choice of $m$, $\chi$ contains a monochromatic copy of $K_k$, as required.
\end{proof}
